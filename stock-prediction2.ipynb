{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rkaya\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# List of investors to track\n",
    "investors = [\n",
    "    \"Bill Ackman\", \"Benjamin Graham\", \"Warren Buffett\", \"John Bogle\", \"Cathie Wood\", \n",
    "    \"Peter Lynch\", \"Carl Icahn\", \"Chamath Palihapitiya\", \"George Soros\", \"Sallie Krawcheck\",\n",
    "    \"John Templeton\", \"David Gardner\", \"Tom Gardner\", \"Rep. Nancy Pelosi\", \n",
    "    \"Rep. Dan Crenshaw\", \"Sen. Susan Collins\", \"Rep. Brian Higgins\"\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Warren Buffett...\n",
      "No filings found for Warren Buffett.\n",
      "\n",
      "Processing Bill Ackman...\n",
      "No filings found for Bill Ackman.\n",
      "\n",
      "Processing Carl Icahn...\n",
      "No filings found for Carl Icahn.\n",
      "\n",
      "Processing George Soros...\n",
      "No filings found for George Soros.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# CIKs for selected investors or firms\n",
    "investors = {\n",
    "    \"Warren Buffett\": \"0001067983\",\n",
    "    \"Bill Ackman\": \"0001336528\",\n",
    "    \"Carl Icahn\": \"0000935214\",\n",
    "    \"George Soros\": \"0001029160\",\n",
    "}\n",
    "\n",
    "SEC_BASE_URL = \"https://www.sec.gov\"\n",
    "\n",
    "# Function to fetch the latest 13F-HR filing link for a given CIK\n",
    "def get_latest_13f_filing(cik):\n",
    "    search_url = f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik}&type=13F-HR&count=10\"\n",
    "    response = requests.get(search_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        filing_links = [\n",
    "            SEC_BASE_URL + link[\"href\"]\n",
    "            for link in soup.find_all(\"a\", href=True)\n",
    "            if \"Archives\" in link[\"href\"]\n",
    "        ]\n",
    "        return filing_links[0] if filing_links else None\n",
    "    return None\n",
    "\n",
    "\n",
    "# Function to extract holdings from a filing\n",
    "def extract_holdings(filing_url):\n",
    "    response = requests.get(filing_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        table_rows = soup.find_all(\"tr\")\n",
    "        holdings = []\n",
    "        for row in table_rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) > 1:\n",
    "                try:\n",
    "                    stock = cells[0].text.strip()  # Adjust based on column order\n",
    "                    shares = cells[1].text.strip().replace(\",\", \"\")\n",
    "                    holdings.append((stock, int(shares)))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return holdings\n",
    "    return []\n",
    "\n",
    "# Process each investor\n",
    "for investor, cik in investors.items():\n",
    "    print(f\"\\nProcessing {investor}...\")\n",
    "    filing_url = get_latest_13f_filing(cik)\n",
    "    if filing_url:\n",
    "        print(f\"Filing URL: {filing_url}\")\n",
    "        holdings = extract_holdings(filing_url)\n",
    "        print(f\"Holdings for {investor}:\")\n",
    "        for stock, shares in holdings[:10]:  # Show top 10 holdings\n",
    "            print(f\"  {stock}: {shares} shares\")\n",
    "    else:\n",
    "        print(f\"No filings found for {investor}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
